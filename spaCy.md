spaCy has several pretrained language models which differ by:

- Language (e.g., English, German, etc.)

- Size (small = faster, large = more accurate)

- Components (e.g., POS tagging, NER, parsing, vectors)


| Model             | Size        | Features                                           | Speed       | Accuracy                |
| ----------------- | ----------- | -------------------------------------------------- | ----------- | ----------------------- |
| `en_core_web_sm`  | Small       | ‚úî Tokenizer, POS, NER, Parsing (no word vectors)   | ‚ö° Fast      | üëç Good for quick tasks |
| `en_core_web_md`  | Medium      | ‚úî Everything above + medium-sized **word vectors** | ‚öñÔ∏è Balanced | Better                  |
| `en_core_web_lg`  | Large       | ‚úî All components + **large word vectors**          | üê¢ Slower   | ‚úÖ High                  |
| `en_core_web_trf` | Transformer | Uses **BERT-like transformer** (e.g., RoBERTa)     | üß† Slowest  | üíé Highest accuracy     |

**How to See All Available Models:** `python -m spacy validate`

**How to download a model:** `python -m spacy download en_core_web_md`

**Use in Python:**

import spacy

`nlp = spacy.load("en_core_web_md")`

