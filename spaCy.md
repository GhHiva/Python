spaCy has several pretrained language models which differ by:

- Language (e.g., English, German, etc.)

- Size (small = faster, large = more accurate)

- Components (e.g., POS tagging, NER, parsing, vectors)


| Model             | Size        | Features                                           | Speed       | Accuracy                |
| ----------------- | ----------- | -------------------------------------------------- | ----------- | ----------------------- |
| `en_core_web_sm`  | Small       | âœ” Tokenizer, POS, NER, Parsing (no word vectors)   | âš¡ Fast      | ğŸ‘ Good for quick tasks |
| `en_core_web_md`  | Medium      | âœ” Everything above + medium-sized **word vectors** | âš–ï¸ Balanced | Better                  |
| `en_core_web_lg`  | Large       | âœ” All components + **large word vectors**          | ğŸ¢ Slower   | âœ… High                  |
| `en_core_web_trf` | Transformer | Uses **BERT-like transformer** (e.g., RoBERTa)     | ğŸ§  Slowest  | ğŸ’ Highest accuracy     |

**How to See All Available Models: python -m spacy validate**
